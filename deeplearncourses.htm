<html xmlns:v="urn:schemas-microsoft-com:vml"
xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 14">
<meta name=Originator content="Microsoft Word 14">
<link rel=File-List href="deeplearncourses-Dateien/filelist.xml">
<title>Courses ISSDL 2018</title>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>Piro Lennart</o:Author>
  <o:LastAuthor>Piro Lennart</o:LastAuthor>
  <o:Revision>9</o:Revision>
  <o:Created>2018-06-13T09:14:00Z</o:Created>
  <o:LastSaved>2018-06-13T09:24:00Z</o:LastSaved>
  <o:Pages>11</o:Pages>
  <o:Words>8107</o:Words>
  <o:Characters>51076</o:Characters>
  <o:Company>Reply AG</o:Company>
  <o:Lines>425</o:Lines>
  <o:Paragraphs>118</o:Paragraphs>
  <o:CharactersWithSpaces>59065</o:CharactersWithSpaces>
  <o:Version>14.00</o:Version>
 </o:DocumentProperties>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
 </o:OfficeDocumentSettings>
</xml><![endif]-->
<link rel=dataStoreItem href="deeplearncourses-Dateien/item0006.xml"
target="deeplearncourses-Dateien/props007.xml">
<link rel=themeData href="deeplearncourses-Dateien/themedata.thmx">
<link rel=colorSchemeMapping
href="deeplearncourses-Dateien/colorschememapping.xml">
<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:SpellingState>Clean</w:SpellingState>
  <w:GrammarState>Clean</w:GrammarState>
  <w:TrackMoves>false</w:TrackMoves>
  <w:TrackFormatting/>
  <w:HyphenationZone>21</w:HyphenationZone>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>DE</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
  </w:Compatibility>
  <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="true"
  DefSemiHidden="true" DefQFormat="false" DefPriority="99"
  LatentStyleCount="267">
  <w:LsdException Locked="false" Priority="0" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" Name="toc 9"/>
  <w:LsdException Locked="false" Priority="35" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" Priority="10" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" Priority="1" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" Priority="11" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" Priority="22" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" Priority="59" SemiHidden="false"
   UnhideWhenUsed="false" Name="Table Grid"/>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" UnhideWhenUsed="false" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" SemiHidden="false"
   UnhideWhenUsed="false" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" SemiHidden="false"
   UnhideWhenUsed="false" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" SemiHidden="false"
   UnhideWhenUsed="false" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" SemiHidden="false"
   UnhideWhenUsed="false" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" SemiHidden="false"
   UnhideWhenUsed="false" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" QFormat="true" Name="TOC Heading"/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536859905 -1073732485 9 0 511 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin-top:0cm;
	margin-right:0cm;
	margin-bottom:10.0pt;
	margin-left:0cm;
	line-height:115%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
a:link, span.MsoHyperlink
	{mso-style-noshow:yes;
	mso-style-priority:99;
	color:blue;
	mso-themecolor:hyperlink;
	text-decoration:underline;
	text-underline:single;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-noshow:yes;
	mso-style-priority:99;
	color:purple;
	mso-themecolor:followedhyperlink;
	text-decoration:underline;
	text-underline:single;}
p.MsoListParagraph, li.MsoListParagraph, div.MsoListParagraph
	{mso-style-priority:34;
	mso-style-unhide:no;
	mso-style-qformat:yes;
	margin-top:0cm;
	margin-right:0cm;
	margin-bottom:10.0pt;
	margin-left:36.0pt;
	mso-add-space:auto;
	line-height:115%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
p.MsoListParagraphCxSpFirst, li.MsoListParagraphCxSpFirst, div.MsoListParagraphCxSpFirst
	{mso-style-priority:34;
	mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-type:export-only;
	margin-top:0cm;
	margin-right:0cm;
	margin-bottom:0cm;
	margin-left:36.0pt;
	margin-bottom:.0001pt;
	mso-add-space:auto;
	line-height:115%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
p.MsoListParagraphCxSpMiddle, li.MsoListParagraphCxSpMiddle, div.MsoListParagraphCxSpMiddle
	{mso-style-priority:34;
	mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-type:export-only;
	margin-top:0cm;
	margin-right:0cm;
	margin-bottom:0cm;
	margin-left:36.0pt;
	margin-bottom:.0001pt;
	mso-add-space:auto;
	line-height:115%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
p.MsoListParagraphCxSpLast, li.MsoListParagraphCxSpLast, div.MsoListParagraphCxSpLast
	{mso-style-priority:34;
	mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-type:export-only;
	margin-top:0cm;
	margin-right:0cm;
	margin-bottom:10.0pt;
	margin-left:36.0pt;
	mso-add-space:auto;
	line-height:115%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-size:10.0pt;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
@page WordSection1
	{size:841.9pt 595.3pt;
	mso-page-orientation:landscape;
	margin:70.85pt 70.85pt 70.85pt 2.0cm;
	mso-header-margin:35.4pt;
	mso-footer-margin:35.4pt;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Normale Tabelle";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin:0cm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
table.MsoTableGrid
	{mso-style-name:Tabellenraster;
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-priority:59;
	mso-style-unhide:no;
	border:solid windowtext 1.0pt;
	mso-border-alt:solid windowtext .5pt;
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-border-insideh:.5pt solid windowtext;
	mso-border-insidev:.5pt solid windowtext;
	mso-para-margin:0cm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
table.MsoTableLightShading
	{mso-style-name:"Helle Schattierung";
	mso-tstyle-rowband-size:1;
	mso-tstyle-colband-size:1;
	mso-style-priority:60;
	mso-style-unhide:no;
	border-top:solid black 1.0pt;
	mso-border-top-themecolor:text1;
	border-left:none;
	border-bottom:solid black 1.0pt;
	mso-border-bottom-themecolor:text1;
	border-right:none;
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin:0cm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Calibri","sans-serif";
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;
	color:black;
	mso-themecolor:text1;
	mso-themeshade:191;
	mso-fareast-language:EN-US;}
table.MsoTableLightShadingFirstRow
	{mso-style-name:"Helle Schattierung";
	mso-table-condition:first-row;
	mso-style-priority:60;
	mso-style-unhide:no;
	mso-tstyle-border-top:1.0pt solid black;
	mso-tstyle-border-top-themecolor:text1;
	mso-tstyle-border-left:cell-none;
	mso-tstyle-border-bottom:1.0pt solid black;
	mso-tstyle-border-bottom-themecolor:text1;
	mso-tstyle-border-right:cell-none;
	mso-tstyle-border-insideh:cell-none;
	mso-tstyle-border-insidev:cell-none;
	mso-para-margin-top:auto;
	mso-para-margin-bottom:auto;
	line-height:normal;
	mso-ansi-font-weight:bold;
	mso-bidi-font-weight:bold;}
table.MsoTableLightShadingLastRow
	{mso-style-name:"Helle Schattierung";
	mso-table-condition:last-row;
	mso-style-priority:60;
	mso-style-unhide:no;
	mso-tstyle-border-top:1.0pt solid black;
	mso-tstyle-border-top-themecolor:text1;
	mso-tstyle-border-left:cell-none;
	mso-tstyle-border-bottom:1.0pt solid black;
	mso-tstyle-border-bottom-themecolor:text1;
	mso-tstyle-border-right:cell-none;
	mso-tstyle-border-insideh:cell-none;
	mso-tstyle-border-insidev:cell-none;
	mso-para-margin-top:auto;
	mso-para-margin-bottom:auto;
	line-height:normal;
	mso-ansi-font-weight:bold;
	mso-bidi-font-weight:bold;}
table.MsoTableLightShadingFirstCol
	{mso-style-name:"Helle Schattierung";
	mso-table-condition:first-column;
	mso-style-priority:60;
	mso-style-unhide:no;
	mso-ansi-font-weight:bold;
	mso-bidi-font-weight:bold;}
table.MsoTableLightShadingLastCol
	{mso-style-name:"Helle Schattierung";
	mso-table-condition:last-column;
	mso-style-priority:60;
	mso-style-unhide:no;
	mso-ansi-font-weight:bold;
	mso-bidi-font-weight:bold;}
table.MsoTableLightShadingOddColumn
	{mso-style-name:"Helle Schattierung";
	mso-table-condition:odd-column;
	mso-style-priority:60;
	mso-style-unhide:no;
	mso-tstyle-shading:silver;
	mso-tstyle-shading-themecolor:text1;
	mso-tstyle-shading-themetint:63;
	mso-tstyle-border-left:cell-none;
	mso-tstyle-border-right:cell-none;
	mso-tstyle-border-insideh:cell-none;
	mso-tstyle-border-insidev:cell-none;}
table.MsoTableLightShadingOddRow
	{mso-style-name:"Helle Schattierung";
	mso-table-condition:odd-row;
	mso-style-priority:60;
	mso-style-unhide:no;
	mso-tstyle-shading:silver;
	mso-tstyle-shading-themecolor:text1;
	mso-tstyle-shading-themetint:63;
	mso-tstyle-border-left:cell-none;
	mso-tstyle-border-right:cell-none;
	mso-tstyle-border-insideh:cell-none;
	mso-tstyle-border-insidev:cell-none;}
</style>
<![endif]--><!--[if gte mso 9]><xml>
 <o:shapedefaults v:ext="edit" spidmax="1026"/>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:shapelayout v:ext="edit">
  <o:idmap v:ext="edit" data="1"/>
 </o:shapelayout></xml><![endif]-->
</head>

<body lang=DE link=blue vlink=purple style='tab-interval:35.4pt'>

<div class=WordSection1>

<table class=MsoTableLightShading border=1 cellspacing=0 cellpadding=0
 width="100%" style='width:100.0%;border-collapse:collapse;border:none;
 mso-border-top-alt:solid black 1.0pt;mso-border-top-themecolor:text1;
 mso-border-bottom-alt:solid black 1.0pt;mso-border-bottom-themecolor:text1;
 mso-yfti-tbllook:1696;mso-padding-alt:0cm 5.4pt 0cm 5.4pt'>
 <tr style='mso-yfti-irow:-1;mso-yfti-firstrow:yes;mso-row-margin-right:.8%'>
  <td width="15%" valign=top style='width:15.5%;border-top:solid black 1.0pt;
  mso-border-top-themecolor:text1;border-left:none;border-bottom:solid black 1.0pt;
  mso-border-bottom-themecolor:text1;border-right:none;padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal align=center style='margin-bottom:0cm;margin-bottom:.0001pt;
  text-align:center;line-height:normal;mso-yfti-cnfc:5'><b><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Sessions<o:p></o:p></span></b></p>
  </td>
  <td width="27%" valign=top style='width:27.9%;border-top:solid black 1.0pt;
  mso-border-top-themecolor:text1;border-left:none;border-bottom:solid black 1.0pt;
  mso-border-bottom-themecolor:text1;border-right:none;padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal align=center style='margin-bottom:0cm;margin-bottom:.0001pt;
  text-align:center;line-height:normal;mso-yfti-cnfc:1'><b><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Course 1<o:p></o:p></span></b></p>
  </td>
  <td width="27%" colspan=2 valign=top style='width:27.9%;border-top:solid black 1.0pt;
  mso-border-top-themecolor:text1;border-left:none;border-bottom:solid black 1.0pt;
  mso-border-bottom-themecolor:text1;border-right:none;padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal align=center style='margin-bottom:0cm;margin-bottom:.0001pt;
  text-align:center;line-height:normal;mso-yfti-cnfc:1'><b><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Course 2<o:p></o:p></span></b></p>
  </td>
  <td width="27%" colspan=2 valign=top style='width:27.9%;border-top:solid black 1.0pt;
  mso-border-top-themecolor:text1;border-left:none;border-bottom:solid black 1.0pt;
  mso-border-bottom-themecolor:text1;border-right:none;padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal align=center style='margin-bottom:0cm;margin-bottom:.0001pt;
  text-align:center;line-height:normal;mso-yfti-cnfc:1'><b><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Course 3<o:p></o:p></span></b></p>
  </td>
  <td style='mso-cell-special:placeholder;border:none;padding:0cm 0cm 0cm 0cm'
  width="0%"><p class='MsoNormal'>&nbsp;</td>
 </tr>
 <tr style='mso-yfti-irow:0'>
  <td width="15%" valign=top style='width:15.5%;border:none;mso-border-top-alt:
  solid black 1.0pt;mso-border-top-themecolor:text1;background:#FF6363;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Mo,
  9:30-11:15<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Mo,
  16:45-18:30<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Tu,
  11:45-13:30<o:p></o:p></span></b></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.48%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Sun-Yuan Kung, Princeton
  University<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>A Methodical and Cost-effective Approach to
  Optimization/Generalization of Deep Learning Networks<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTRODUCTORY<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Summary</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  This course will start with the introduction of two basic machine learning
  subsystems: Feature Engineering (e.g. CNN for Image/Speech Feature
  Extraction) and Label Engineering, e.g. Multi-layer Perceptron (MLP). The
  great success of DNN in broad applications of deep learning networks hinges
  upon the rich nonlinear space embedded in their nonlinear hidden (neuron)
  layers. However, we face two major challenges: (1) the curse of depth and (2)
  the ad hoc nature of deep learning. Fortunately, many solutions have been
  proposed to effectively overcome the 'vanishing gradient' problem due to the
  curse of depth. In particular, we shall elaborate (a) cross-entropy (with
  amplified gradients) effective to surrogate the 0-1 loss; (b) the merit of
  ReLu-neurons and (c) the vital roles of bagging, mini-batch, and dropout.<br>
  It is widely recognized that the ad hoc nature of deep learning renders its
  success at the mercy of trial- and-errors. To combat this problem, we
  advocate a methodic and cost-effective learning paradigm (MINDnet) to train
  multi-layer networks. In particular, MINDnet elegantly circumvents the curse
  of depth by harnessing a new notion of omni-present supervision, i.e.
  teachers hidden within a sort of 'Trojan-horse' traveling along with the
  forward-propagating signals from the input to hidden layers. Therefore, one
  can directly harvest teacher’s information at any hidden-layer in the MLP,
  i.e. , no- propagation (NP) will be required. This will lead to a new and
  slender 'inheritance layer' to summarize (inherit) all the discriminant
  information embedded in the previous layer. Moreover, by augmenting the
  inheritance layer with additional randomized nodes and applying again
  back-propagation (BP) learning, the discriminant power of the network can be
  further enhanced. Finally, we have compared MINDnet with several popular
  learning models on real-world datasets, including CIFAR images, MNIST,
  mHealth, HAR, Yale, Olivetti, Essex datsets. Our preliminary simulation seems
  to suggest some superiority by MINDnet. For example, for the CIFAR-10
  dataset, 97.9%+/-0.16% (MINDnet) &gt; 97.4% (CutNet) &gt; 96.0% (DenseNet)
  &gt; 93.6% (ResNet). <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Syllabus</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  Session 1:<br>
  Introduction of two basic machine learning subsystems:<br>
  - Feature Engineering: CNN for Image/Speech Feature Extraction<br>
  - Label Engineering: multi-layer deep learning networks<br>
  Introduce supplementary (SVM-based) subsystems for validation and prediction
  and highlight their<br>
  vital roles in optimization and generalization.<br>
  Introduce an effective surrogate function (to surrogate the 0-1 loss) in the
  training phase:<br>
  - How/why cross-entropy offers amplified gradients.<br>
  <br>
  Introduce network friendly training metrics:<br>
  • equivalent optimization metrics: LSE (Gauss), FDR (Fisher) and Mutual
  Information (Shannon).<br>
  <br>
  Session 2:<br>
  Derive Back-propagation (BP) Algorithm for<br>
  - back-propagation of 1st-order (gradient) and 2nd-order (Hessian) functions<br>
  Discuss effective remedies for tackling the vanishing gradient problem in
  deep networks:<br>
  - ReLu-neuron<br>
  - bagging, minim-batch, and dropout<br>
  Introduce MINDnet learning paradigm:<br>
  - Why the acronym MIND: Monotonically INcreasing Discriminant (MIND).<br>
  - A simple solution to overcome the Curse of Depth: No-propagation (NP)
  learning algorithm<br>
  o How to harness the teacher information “hidden” in the hidden layer?<br>
  - How to use a small number of nodes (inheritance layer) to fully summarize
  (inherit) all the<br>
  useful information embedded in the entire previous layer?<br>
  - To highlight the vital role of BP/NP hybrid learning.<br>
  Session 3:<br>
  Elaborate the detailed procedure to successively construct MINDnets with
  gradually growing depth:<br>
  <br>
  • (vertical expansion)= full Inheritance with a small number of nodes<br>
  • (horizontal expansion)= Inheritance Theorem + random nodes<br>
  <br>
  Demonstrate that the prediction accuracy indeed improves as the MINDnet grows
  deeper:<br>
  • Via a Synthetic dataset, we shall conduct an extensive comparative study of
  various machine<br>
  learning tools in the literature.<br>
  - compare MINDnet with other existing networks based real-world datasets such
  as CIFAR,<br>
  MNIST, Yale, Olivetti, Essex, mHealth, HAR, etc.<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>References</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  1. I. Goodfellow, Y. Bengio, and A. Courville, Deep learning. MIT Press,
  Cambridge, UAA, 2016.<br>
  2. C.M. Bishop, Pattern Recognition and Machine Learning, Berlin: Springer.<br>
  3. S.Y. Kung, Digitial Neural Networks. Prentice Hall, 1993.<br>
  4. S.Y. Kung, Kernal Methods and Machine Learning, Cambridge Press, 2014.<br>
  5. Zhang, C., Bengio, S., Hardt, M., Recht, B., &amp; Vinyals, O. (2016).
  Understanding deep learning requires rethinking generalization.&nbsp;arXiv
  preprint arXiv:1611.03530.<br>
  6. Koh, P. W., &amp; Liang, P. (2017). Understanding black-box predictions
  via influence functions.&nbsp;arXiv preprint arXiv:1703.04730. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Pre-requisites</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  Linear Algebra;Understanding of the design and analysis of algorithms <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="27%" colspan=2 valign=top style='width:27.52%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Ponnuthurai N Suganthan,
  Nanyang Technological University<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Learning Algorithms for Classification, Forecasting
  and Visual Tracking<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTRODUCTORY/INTERMEDIATE<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Summary</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  This presentation will primarily focus on learning algorithms with reduced
  iterations or no iterations at all. Some of the algorithms have closed form
  solutions. Some of the algorithms do not adjust the structures once
  constructed. The main algorithms considered in this talk are randomized
  neural networks, kernel ridge regression and random forest. These
  non-iterative methods have attracted attention of researchers due to their
  high performance in terms of accuracy as well as their ability to train fast
  due to their non-iterative properties or closed form training solutions. For
  example, the random forest deliver the top classification performance. The
  presentation will also include the basic methods as well as their state of
  the art realizations. These algorithms will be benchmarked using
  classification, time series forecasting and visual tracking datasets. Future
  research directions will also be suggested. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Syllabus</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  Non-iterative algorithms or algorithms with closed-form training solutions<br>
  Randomization based neural networks and their variants<br>
  Kernel Ridge Regression and their variants<br>
  Random Forest and their variants<br>
  Applications of the above methods in classification, time series and visual
  tracking<br>
  Benchmarking of these methods <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>References</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  (Additional References will be included in the lecture materials)<br>
  X Qiu, PN Suganthan, GAJ Amaratunga, Ensemble incremental learning Random
  Vector Functional Link network for short-term electric load forecasting<br>
  Knowledge-Based Systems 145, 182-196, 2018.<br>
  L Zhang, PN Suganthan, Benchmarking Ensemble Classifiers with Novel
  Co-Trained Kernel Ridge Regression and Random Vector Functional Link Ensembles
  [Research Frontier], IEEE Computational Intelligence Magazine 12 (4), 61-72,
  2017.<br>
  L Zhang, PN Suganthan, Visual tracking with convolutional random vector
  functional link network, IEEE Transactions on Cybernetics 47 (10), 3243-3253.<br>
  L Zhang, PN Suganthan, Robust visual tracking via co-trained Kernelized
  correlation filters, Pattern Recognition 69, 82-93, 2017.<br>
  L Zhang, PN Suganthan, A survey of randomized algorithms for training neural
  networks, Information Sciences 364, 146-155, 2016.<br>
  L Zhang, PN Suganthan, Oblique decision tree ensemble via multisurface
  proximal support vector machine, IEEE Transactions on Cybernetics 45 (10),
  2165-2176, 2015. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Pre-requisites</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  Basic knowledge of neural networks, pattern classification, decision trees
  will be advantageous. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.5%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Mohammed J. Zaki, Rensselaer
  Polytechnic Institute<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Introductory Tutorial on Regression and Deep Learning<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTRODUCTORY<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Summary</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  In this tutorial, we will be going over the basics of regression and deep learning.
  We will start with linear regression, and then consider logistic regression.
  We will move on to artificial neural networks and deep learning. The focus
  will be on the underlying concepts, mathematics, and algorithms. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Syllabus</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  1. Linear Regression: Ordinary least squares, multiple regression, kernel
  regression, L1 regression<br>
  2. Logistic Regression: binary and multi-class regression<br>
  3. Neural networks: Multilayer perceptrons (MLPs), backpropagation<br>
  4. Recurrent Neural Networks (RNNs): RNNs, backpropagation in time,
  bidirectional RNNs<br>
  5. Gated RNNs: Long short-term memory (LSTM), gated recurrent units (GRU)<br>
  6. Convolutional Neural Networks (CNNs): convolutions, activations, deep CNNs<br>
  7. Evaluation: regression modelling, assessment <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>References</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  * Ian Goodfellow, Yoshua Bengio, Aaron Courville, Deep learning, MIT Press,
  2016. <br>
  * Mohammed J. Zaki, Wagner Meira, Jr., Data Mining and Analysis: Fundamental
  Concepts and Algorithms, Cambridge University Press, 2014. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Pre-requisites</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  This is an introductory tutorial, but it assumes some familiarity with linear
  algebra, and probability and statistics. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
 </tr>
 <tr style='mso-yfti-irow:1'>
  <td width="15%" valign=top style='width:15.5%;border:none;background:#FFAE00;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Mo,
  11:45-13:30<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Mo,
  19:00-20:45<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Tu,
  14:30-16:15<o:p></o:p></span></b></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.48%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Tülay Adal&#305;, University of
  Maryland, Baltimore County<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Data Fusion through Matrix and Tensor Decompositions:
  Linear, Multilinear, and Nonlinear Models and their Applications<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTRODUCTORY/INTERMEDIATE<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Summary</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  In many fields today, multiple sets of data are readily available. These
  might either refer to multimodal data where information about a given
  phenomenon is obtained through different types of acquisition techniques, or
  multiset data where the datasets are all of the same type but might be
  acquired from different subjects, at different time points, or under
  different conditions. Joint analysis of this data—its fusion—promises a more
  comprehensive and informative view of the task at hand than performing
  separate analyses, and, if probed carefully, may open new venues and answer
  questions we might not have even thought of asking when working with a single
  modality or dataset. Models based on matrix or tensor decompositions provide
  attractive solutions for fusion of both multi-modal and multiset data. These
  models minimize the assumptions—which is attractive as very little can be
  assumed about the relationship among multiple datasets—and at the same time,
  they can maximally exploit the interactions within and across the datasets. <br>
  This class will provide an overview of the main methods for matrix and tensor
  decompositions and the models that have been successfully applied for fusion
  of multiple datasets. An important focus is on the interrelated concepts of
  uniqueness, diversity, and interpretability. Diversity refers to any
  structural, numerical, or statistical property or assumption on the data that
  contributes to the identifiability of the model, which is key for
  interpretability, the ability to attach a physical meaning to the final
  decomposition. The relevance of these concepts as well as the challenges that
  remain are highlighted through a number of numerical and practical examples
  in various fields. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Syllabus</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  <br>
  I. Basic matrix/tensor decompositions, identifiability &amp; uniqueness<br>
  * SVD/PCA <br>
  * CP decomposition <br>
  * CCA and MCCA<br>
  * ICA and IVA<br>
  * Other relevant matrix/tensor decompositions <br>
  II. Models for fusion of multiset and multimodal data<br>
  * IVA, transposed IVA<br>
  * Joint ICA and Parallel ICA<br>
  * Coupled matrix and tensor decompositions <br>
  * Nonlinear extensions<br>
  III. Performance evaluation, model comparison/selection<br>
  Examples in medical imaging, video processing, and recommender systems among
  others<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>References</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  D. Lahat, T. Adali and C. Jutten, 'Multimodal data fusion: An overview of
  methods, challenges, and prospects,' Proc. IEEE, vol. 103, no. 9, pp.
  1449-1477, Sep. 2015. <a href="https://hal.archives-ouvertes.fr/hal-01179853">https://hal.archives-ouvertes.fr/hal-01179853</a>
  <br>
  <br>
  T. Adali, Y. Levin-Schwartz, and V. D. Calhoun, 'Multimodal data fusion using
  source separation: Two effective models based on ICA and IVA and their
  properties,' Proc. IEEE, vol. 103, no. 9, pp. 1478-1493, Sep. 2015.<br>
  <br>
  T. Adali, M. Anderson, and G.-S. Fu, 'Diversity in independent component and
  vector analyses: Identifiability, algorithms, and applications in medical
  imaging,' IEEE Signal Processing Magazine, vol. 31, no. 3, pp. 18-33, May
  2014.<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Pre-requisites</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  Basic matrix algebra, probability and statistics, and background in
  estimation theory is desirable but not required. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="27%" colspan=2 valign=top style='width:27.52%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Sergei V. Gleyzer, University
  of Florida<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Feature Extraction, End-end Deep Learning and
  Applications to Very Large Scientific Data: Rare Signal Extraction,
  Uncertainty Estimation and Realtime Machine Learning Applications in Software
  and Hardware<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTRODUCTORY/INTERMEDIATE<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>[no description yet]<o:p></o:p></span></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.5%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Michael Gschwind, IBM Global
  Chief Data Office<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Deploying Deep Learning at Enterprise Scale<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTRODUCTORY/INTERMEDIATE<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Summary</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  A confluence of new artificial neural network architectures and unprecedented
  compute capabilities based on numeric accelerators has reinvigorated interest
  in Artificial Intelligence based on neural processing. Initial first
  successful deployments in hyperscale internet services are now driving
  broader commercial interest in adopting Deep learning as a design principle
  for cognitive applications in the enterprise. In this class, we will review
  hardware acceleration and co-optimized software frameworks for Deep Learning,
  and discuss model development and deployment to accelerate adoption of Deep
  Learning based solutions for enterprise deployments <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Syllabus</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  Session 1:<br>
  1a. Hardware Foundations of the Great AI Re-Awakening<br>
  1b. Deployment models for DNN Training and Inference<br>
  Session 2:<br>
  Optimized High Performance Training Frameworks<br>
  Session 3:<br>
  Parallel Training Environments <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>References</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  M. Gschwind, Need for Speed: Accelerated Deep Learning on Power, GPU
  Technology Conference, Washington DC, October 2016. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Pre-requisites</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  - <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
 </tr>
 <tr style='mso-yfti-irow:2'>
  <td width="15%" valign=top style='width:15.5%;border:none;background:#7CFF7A;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Mo,
  14:30-16:15<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Tu,
  9:30-11:15<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Tu,
  16:45-18:30<o:p></o:p></span></b></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.48%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Pierre Baldi, University of
  California, Irvine<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Deep Learning: Theory, Algorithms, and Applications
  to the Natural Sciences<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTERMEDIATE/ADVANCED<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Summary</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  The process of learning is essential for building natural or artificial
  intelligent systems. Thus, not surprisingly, machine learning is at the center
  of artificial intelligence today. And deep learning--essentially learning in
  complex systems comprised of multiple processing stages--is at the forefront
  of machine learning. The lectures will provide an overview of neural networks
  and deep learning with an emphasis on first principles and theoretical
  foundations. The lectures will also provide a brief historical perspective of
  the field. Applications will be focused on difficult problems in the natural
  sciences, from physics, to chemistry, and to biology. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Syllabus</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  1: Introduction and Historical Background. Building Blocks. Architectures.
  Shallow Networks. Design and Learning. <br>
  2: Deep Networks. Backpropagation. Underfitting, Overfitting, and Tricks of
  the Trade.<br>
  3: Two-Layer Networks. Universal Approximation Properties. Compressive and
  Expansive Autoencoders. Network capacity.<br>
  4: Learning in the Machine. Local Learning and the Learning Channel. Hebbian
  Learning. Dropout. Optimality of BP and Random BP.<br>
  5: Architectures (Convolutional, Siamese, GANs, etc). Applications. <br>
  6: Recurrent Networks. Hopfield model. Boltzmann machines.<br>
  7: Recursive and Recurrent Networks. Design and Learning. Inner and Outer
  Approaches.<br>
  8: Applications to Physics (High Energy, Neutrino, Antimatter, Dark Matter,
  etc.)<br>
  9: Applications to Chemistry (Molecules, Reactions, etc).<br>
  10: Applications to Biology (Proteins, DNA, Biomedical Imaging, etc). <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>References</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  tbc. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Pre-requisites</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  Basic algebra, calculus, and probability at the introductory college level.
  Some previous knowledge of machine learning could be useful but not required.
  <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="27%" colspan=2 valign=top style='width:27.52%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Hermann Ney, RWTH Aachen
  University<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Speech Recognition and Machine Translation: From
  Statistical Decision Theory to Machine Learning and Deep Neural Networks<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTERMEDIATE/ADVANCED<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Summary</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  The last 40 years have seen a dramatic progress in machine learning and
  statistical methods for speech and language processing like speech
  recognition, handwriting recognition and machine translation. Many of the key
  statistical concepts had originally been developed for speech recognition and
  language translation. Examples of such key concepts are the Bayes decision
  rule for minimum error rate and sequence-to-sequence processing using
  approaches like the alignment mechanism based on hidden Markov models and the
  attention mechanism based on neural networks. Recently the accuracy of speech
  recognition and machine translation could be improved significantly by the
  use of artificial neural networks, such as deep feedforward multi-layer
  perceptrons and recurrent neural networks (incl. long short-term memory
  extension). We will discuss these approaches in detail and how they form part
  of the probabilistic approach. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Syllabus</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  Part 1: Statistical Decision Theory, Machine Learning and Neural Networks.<br>
  Part 2: Speech Recognition<br>
  (Time Alignment, Hidden Markov models, sequence-to-sequence<br>
  processing, neural nets, attention models).<br>
  Part 3: Machine Translation<br>
  (Word Alignment, Hidden Markov models, sequence-to-sequence<br>
  processing, neural nets, attention models). <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>References</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  * Bourlard, H. and Morgan, N., Connectionist Speech Recognition - A Hybrid<br>
  Approach, Kluwer Academic Publishers, ISBN 0-7923-9396-1, 1994.<br>
  * L. Deng, D. Yu: Deep learning: methods and applications.<br>
  Foundations and Trends in Signal Processing, Vol. 7, No. 3–4,<br>
  pp. 197-387, 2014.<br>
  * D. Jurafsky, J. H. Martin: Speech and Language Processing.<br>
  Third edition draft, pdf; August 28, 2017.<br>
  * Y. Goldberg: Neural Network Methods in Natural Language Processing.<br>
  Morgan &amp; Claypool Publishers, Draft, pdf; August 2016.<br>
  * P. Koehn: Statistical Machine Translation,<br>
  Cambridge University Press, 2010.<br>
  In addition: Draft of Chapter 13: Neural Machine Translation,<br>
  pdf, September 22, 2017. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Pre-requisites</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  Familiarity with linear algebra, numerical mathematics, probability and
  statistics, elementary machine learning. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.5%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Eric P. Xing, Carnegie Mellon
  University<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>A Statistical Machine Learning Perspective of Deep
  Learning: Algorithm, Theory, Scalable Computing<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTERMEDIATE/ADVANCED<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Summary</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><br>
  In this tutorial I am going to explain the connections between the 'new wave'
  of multi-layer neural network inspired models in 'Deep Learning', with the
  well founded probabilistic graphical models, Bayesian inference, kernel
  methods, and many other long standing statistical learning methodologies
  studied in the broader machine learning community, and discuss the principles
  behind inference, learning, evaluations, and argumentation of these
  techniques. Then I will focus on stratifying various deep generative models
  with a unified statistical framework to better understand their behaviors,
  relationships, and new opportunities. Finally I will discuss the
  computational challenges in large scale deep learning, and discuss algorithm
  design, system design, and standardized universal platforms for computing
  support in deep learning. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Syllabus</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>References</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span lang=EN-US style='color:black;mso-themecolor:text1;
  mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Pre-requisites</span></b><span
  lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-ansi-language:EN-US;mso-no-proof:yes'><o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
 </tr>
 <tr style='mso-yfti-irow:3'>
  <td width="15%" valign=top style='width:15.5%;border:none;background:#FFE213;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Tu,
  19:00-20:45<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>We,
  11:45-13:30<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>We,
  16:45-18:30<o:p></o:p></span></b></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.48%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Joachim M. Buhmann, Swiss
  Federal Institute of Technology Zurich<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Model Selection by Algorithm Validation<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTRODUCTORY/ADVANCED<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  One of the central challenges in machine learning today relates to the high
  parameter complexity of models and their relation to a large amount of
  heterogeneous, noisy data. What is the relevant information in the data to
  select a model / hypothesis from a hypothesis class? Machine learning
  research has answered this question to a scientifically satisfactory degree
  in supervised learning, i.e., classification and regression. Without teacher
  provided guidance, however, model selection and validation still appears to
  be a magic engineering art mostly dominated by heuristics fundamental ML
  algorithms The course willl cover traditional model selection methods like
  AIC, BIC, but also the stability method and a novel approach based on
  information theory. The resulting selection score, called posterior agreement
  criterion, requires hypotheses to agree on two different instances drawn from
  the same data source. Such a robustness criterion captures the spirit of
  cross-validation and ensures that hypotheses of models are selected according
  to the signal in the data and are not significantly affected by noise. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Syllabus</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Algorithms and Gibbs distributions, Maximum Entropy method, AIC, BIC,
  stability selection,<br>
  Information Theoretic Model Validation, algorithms as time evolving posterior
  distributions; examples in approximate sorting, aproximate spanning
  trees,pipeline tuning in biomedical applications. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>References</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  J.M. Buhmann et al., Robust optimization in the presence of uncertainty: A
  generic approach,Journal of Computer and System Sciences 94, pp. 135-166,
  (2018)<br>
  J.M. Buhmann, Information theoretic model validation for clustering, ISIT
  2010 Austin, pp 1398 - 1402, (2010) <br>
  J.M. Buhmann, SIMBAD: Emergence of Pattern Similarity, in Advances in Vision
  and Pattern Recognition, Ed. Marcello Pelillo, Springer, (2013), isbn =
  978-1-4471-5627-7 <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Pre-requisites</span></b><span style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Introductory course in Machine Learning and/or Statistics. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="27%" colspan=2 valign=top style='width:27.52%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Johan Suykens, KU Leuven<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Deep Learning and Kernel Machines<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTRODUCTORY/INTERMEDIATE<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Neural networks &amp; Deep learning and Support vector machines &amp; Kernel
  methods have been among the most powerful and successful techniques in
  machine learning and data driven modelling. Initially, in artificial neural
  networks, the use of one hidden layer feedforward networks was common because
  of their universal approximation property. However, the existence of many
  local minima solutions in the training process was encountered as a drawback.
  Therefore, support vector machines and kernel methods became widely used,
  relying on solving convex optimization problems in classification and
  regression. In the meantime, computing power has increased and data have
  become abundantly available in many applications. As a result, currently one
  can afford training deep models consisting of (many) more layers and
  interconnection weights. Examples of successful deep learning models are
  convolutional neural networks, stacked autoencoders, deep Boltzmann machines,
  deep generative models and generative adversarial networks. In this course we
  will explain several synergies between neural networks, deep learning, least
  squares support vector machines and kernel methods. A key role at this point
  is played by primal and dual model representations and different duality
  principles. In this way the bigger picture will be revealed for neural
  networks, deep learning and kernel machines, and future perspectives will be
  outlined. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Syllabus</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  The material is organized into 3 parts:<br>
  - Part I Neural networks, support vector machines and kernel methods<br>
  <br>
  - Part II Restricted Boltzmann machines, kernel machines and deep learning <br>
  <br>
  - Part III Deep restricted kernel machines and future perspectives. <br>
  <br>
  In Part I a basic introduction is given to support vector machines (SVM) and
  kernel methods with emphasis on their artificial neural networks (ANN)
  interpretations. The latter can be understood in view of primal and dual
  model representations, expressed in terms of the feature map and the kernel
  function, respectively. Related to least squares support vector machines (LS-SVM)
  such characterizations exist for supervised and unsupervised learning,
  including classification, regression, kernel principal component analysis
  (KPCA), kernel spectral clustering (KSC), kernel canonical correlation
  analysis (KCCA), and other. Primal and dual representations are also relevant
  in order to obtain efficient training algorithms, tailored to the nature of
  the given application (high dimensional input spaces versus large data
  sizes). Application examples are given e.g. in black-box weather forecasting,
  pollution modelling, prediction of energy consumption, and community
  detection in networks.<br>
  In Part II we explain how to obtain a so-called restricted kernel machine
  (RKM) representation for least squares support vector machine related models.
  By using a principle of conjugate feature duality it is possible to obtain a
  similar representation as in restricted Boltzmann machines (RBM) (with
  visible and hidden units), which are used in deep belief networks (DBN) and
  deep Boltzmann machines (DBM). The principle is explained both for supervised
  and unsupervised learning. Related to kernel principal component analysis a
  generative model is obtained within the restricted kernel machine framework.
  In such a generative model the trained model is able to generate new data
  examples.<br>
  In Part III deep restricted kernel machines (Deep RKM) are explained which
  consist of restricted kernel machines taken in a deep architecture. In these
  models a distinction is made between depth in a layer sense and depth in a level
  sense. Links and differences with stacked autoencoders and deep Boltzmann
  machines are given. The framework enables to conceive both deep feedforward
  neural networks (DNN) and deep kernel machines, through primal and dual model
  representations. In this case one has multiple feature maps over the
  different levels in companion with multiple kernel functions. By fusing the
  objectives of the different levels (e.g. several KPCA levels followed by an
  LS-SVM classifier) in the deep architecture, the training process becomes
  faster and gives improved solutions. Different training algorithms and
  methods for large data sets will be discussed.<br>
  Finally, based on the newly obtained insights, future perspectives and
  challenges will be outlined. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>References</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Bengio Y., Learning deep architectures for AI, Boston: Now, 2009.<br>
  <br>
  Fischer A., Igel C., Training restricted Boltzmann machines: An introduction.
  Pattern Recognition, 47, 25-39, 2014.<br>
  <br>
  Goodfellow I., Bengio Y., Courville A., Deep learning, Cambridge, MA: MIT
  Press, 2016.<br>
  <br>
  Hinton G.E., What kind of graphical model is the brain?, In Proc. 19th
  International Joint Conference on Artificial Intelligence, pp. 1765-1775,
  2005.<br>
  <br>
  Hinton G.E., Osindero S., Teh Y.-W., A fast learning algorithm for deep
  belief nets, Neural Computation, 18, 1527-1554, 2006.<br>
  <br>
  LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 436-444, 2015.<br>
  <br>
  Lin H.W., Tegmark M., Rolnick D., Why does deep and cheap learning work so
  well?, Journal of Statistical Physics 168 (6), 1223-1247, 2017.<br>
  <br>
  Mall R., Langone R., Suykens J.A.K., Multilevel Hierarchical Kernel Spectral
  Clustering for Real-Life Large Scale Complex Networks, PLOS ONE, e99966,
  9(6), 1-18, 2014.<br>
  <br>
  Mehrkanoon S., Suykens J.A.K., Deep hybrid neural-kernel networks using
  random Fourier features, Neurocomputing, Vol. 298, pp. 46-54, July 2018.<br>
  <br>
  Salakhutdinov R., Learning deep generative models, Annu. Rev. Stat. Appl., 2,
  361-385, 2015.<br>
  <br>
  Scholkopf B., Smola A., Learning with kernels, Cambridge, MA: MIT Press,
  2002.<br>
  <br>
  Schreurs J., Suykens J.A.K., Generative Kernel PCA, ESANN 2018.<br>
  <br>
  Suykens J.A.K., Van Gestel T., De Brabanter J., De Moor B., Vandewalle J.,
  Least squares support vector machines, Singapore: World Scientific, 2002.<br>
  <br>
  Suykens J.A.K., Alzate C., Pelckmans K., Primal and dual model representations
  in kernel-based learning, Statistics Surveys, vol. 4, pp. 148-183, Aug. 2010.<br>
  <br>
  Suykens J.A.K., Deep Restricted Kernel Machines using Conjugate Feature
  Duality, Neural Computation, vol. 29, no. 8, pp. 2123-2163, Aug. 2017.<br>
  <br>
  Vapnik V., Statistical learning theory, New York: Wiley, 1998. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Pre-requisites</span></b><span style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Basics of linear algebra <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.5%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Yudong Zhang, University of
  Leicester<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Convolutional Neural Network and Its Variants<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTRODUCTORY/INTERMEDIATE<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  This lecture will give a brief introduction of convolutional neural network.
  The convolution, pooling, and fully-connected layers shall be introduced. The
  neuroscience under CNN shall be discussed. The hyperparameter optimization of
  CNN shall be presented. Several typical convolutional neural networks shall
  be analyzed and compared, including LeNet, AlexNet, VGG, NiN, GoogleNet,
  ResNet, etc. CNN in segmentation shall be briefly discussed. State-of-the-art
  examples will be used to illustrate CNN approaches. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Syllabus</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  (i) ImageNet and ILSVRC<br>
  (ii) Convolutional neural network, Convolution layers, pooling layer<br>
  (iii) Drop out; Batch normalization; data augmentation<br>
  (iv) Neuroscientific basis, Random search, LeNet<br>
  (v) Transfer learning, AlexNet, 1x1 convolution, VGG<br>
  (vi) Network in network, GoogleNet, ResNet<br>
  (vii) R-CNN, Fast(er) R-CNN, Mask R-CNN<br>
  (viii) Application to cerebral microbleeding, radar imaging, etc. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>References</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  1. Deng, J., W. Dong, R. Socher, L. J. Li, L. Kai and F.-F. Li (2009).
  ImageNet: A large-scale<br>
  hierarchical image database. 2009 IEEE Conference on Computer Vision and
  Pattern Recognition. 248-255.<br>
  2. Ioffe, S. and C. Szegedy (2015). Batch normalization: Accelerating deep
  network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167.<br>
  3. Bergstra, J. and Y. Bengio (2012). Random search for hyper-parameter
  optimization. Journal of Machine Learning Research 13(Feb): 281-305.<br>
  4. Krizhevsky, A., I. Sutskever and G. E. Hinton (2012). ImageNet
  classification with deep convolutional neural networks. Advances in neural
  information processing systems. 1097-1105.<br>
  5. Simonyan, K. and A. Zisserman (2014). Very deep convolutional networks for
  large-scale image recognition. arXiv preprint arXiv:1409.1556.<br>
  6. Szegedy, C., W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan,
  V. Vanhoucke and A. Rabinovich (2015). Going deeper with convolutions. IEEE
  Conference on Computer Vision and Pattern Recognition (CVPR), Boston, MA,
  USA.<br>
  7. He, K., X. Zhang, S. Ren and J. Sun (2016). Deep Residual Learning for
  Image Recognition. 2016 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR). 770-778.<br>
  8. Goodfellow, I., Y. Bengio, A. Courville and Y. Bengio (2016). Deep
  learning, MIT press Cambridge. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Pre-requisites</span></b><span style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Linear Algebra and Calculus, Probability and Statistics, Basics of Image
  Processing, Pattern Recognition and Computer Vision <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
 </tr>
 <tr style='mso-yfti-irow:4'>
  <td width="15%" valign=top style='width:15.5%;border:none;background:#5D7CFD;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>We,
  9:30-11:15<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>We,
  14:30-16:15<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Th,
  11:45-13:30<o:p></o:p></span></b></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.48%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Dimitris N. Metaxas, Rutgers
  University<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Adversarial, Discriminative, Recurrent, and Scalable Deep
  Learning Methods for Human Motion Analytics, Medical Image Analysis, Scene
  Understanding and Image Generation<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>ADVANCED<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  A major challenge of modern machine learning and artificial intelligence is to
  offer understanding and reasoning for domains such as complex real-world
  environments, humans and their activities, medical imaging analytics and real
  world image generation. Addressing such problems for meta knowledge creation
  requires methods that combine deep neural methods, sparse methods, mixed
  norms, AI, and deformable modeling methods. This course will introduce the
  above new concepts and methodologies and will focus on three main topics: a)
  Deriving high order information from complex scenes and human movement for
  event understanding, b) Generative Adversarial Networks (GAN) and deep
  learning for real world image and video generation and story telling, and c)
  Cardiac and Cancer Medical Image Analytics. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Syllabus</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  1. Scene and Human Motion Understanding<br>
  Neural Nets and Nonnegative Matrix Factorization Concepts<br>
  Using NNs for Scene Understanding<br>
  Human Motion Understanding and Sign Language Understanding<br>
  2. GANs and other Deep Learning Methods for scene generation and Story
  Telling<br>
  Introduction to GANs<br>
  Modifications to develop Stack GANs for scene generation from text<br>
  Video Generation from Sentences<br>
  3. Medical Image Analytics<br>
  Deformable Models and Deep Learning<br>
  Cardiac Analytics<br>
  Cancer Diagnosis from Clinical and Preclinical Data <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>References</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  RED-Net: A recurrent encoder-decoder network for video-based face
  alignment.Xi Peng, Rogerio Feris, Xiaoyu Wang, Dimitris Metaxas.
  International Journal of Computer Vision (IJCV), 2018. <br>
  <br>
  CR-GAN: Learning Complete Representations for Multi-view Generation. Yu Tian,
  Xi Peng, Long Zhao, Shaoting Zhang, Dimitris Metaxas International Joint
  Conference on Artificial Intelligence (IJCAI), 2018.<br>
  <br>
  Jointly optimize data augmentation and network training: Adversarial data
  augmentation. Xi Peng, Zhiqiang Tang, Fei Yang, Rogerio S Feris, Dimitris
  Metaxas. IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
  2018.<br>
  <br>
  3D Motion Modeling and Reconstruction of Left Ventricle Wall in Cardiac MRI.
  Dong Yang, Pengxiang Wu, Chaowei Tan, Kilian M Pohl, Leon Axel, Dimitris
  Metaxas. Functional Imaging and Modeling of the Heart, FIMH 2017.<br>
  <br>
  Deep Image-to-Image Recurrent Network with Shape Basis Learning for Automatic
  Vertebra Labeling in Large-Scale 3D CT Volumes. Dong Yang, Tao Xiong, Daguang
  Xu, S Kevin Zhou, Zhoubing Xu, Mingqing Chen, JinHyeong Park, Sasa Grbic,
  Trac D Tran, Sang Peter Chin, Dimitris Metaxas, Dorin Comaniciu.
  International Conference on Medical Image Computing and Computer-Assisted
  Intervention (MICCAI), pp. 498-506, 2017.<br>
  <br>
  Automatic liver segmentation using an adversarial image-to-image network Dong
  Yang, Daguang Xu, S Kevin Zhou, Bogdan Georgescu, Mingqing Chen, Sasa Grbic,
  Dimitris Metaxas, Dorin Comaniciu. International Conference on Medical Image
  Computing and Computer-Assisted Intervention, MICCAI 201 .<br>
  <br>
  Pixel-Wise Neural Cell Instance Segmentation. Jingru Yi, Pengxiang Wu, Daniel
  J Hoeppner, Dimitris Metaxas. Proceedings of the IEEE ISBI, 2018<br>
  <br>
  Multi-Component Deformable Models Coupled with 2D-3D U-Net for Automated
  Probabilistic Segmentation of Cardiac Walls and Blood. Dong Yang, Huang
  Qiaoying, Leon Axel and Dimitris Metaxas Proceedings of IEEE ISBI, 2018.<br>
  <br>
  <br>
  <br>
  Jointly Optimize Data Augmentation and Network Training: Adversarial Data
  Augmentation in Human Pose Estimation. Xi Peng; Zhiqiang Tang, Fei Yang, Rogerio
  S. Feris, Dimitris Metaxas. Procs. CVPR 2018<br>
  <br>
  <br>
  Show Me a Story: Towards Coherent Neural Story Illustration. Hareesh Ravi,
  Lezi Wang, Carlos Muniz, Leonid Sigal, Dimitris Metaxas, Mubbasir Kapadia.
  Procs CVPR 2018.<br>
  <br>
  Improving GANs Using Optimal Transport. Tim Salimans · Han Zhang · Alec
  Radford · Dimitris Metaxas, ICLR 2018<br>
  <br>
  A recurrent encoder-decoder network for sequential face alignment. Xi Peng,
  Rogerio Feris, Xiaoyu Wang, Dimitris Metaxas European Conference on Computer
  Vision (ECCV), 2016<br>
  <br>
  Parallel sparse subspace clustering via joint sample and parameter blockwise
  partition.B Liu, XT Yuan, Y Yu, Q Liu, DN Metaxas. ACM Transactions on
  Embedded Computing Systems (TECS) 16 (3), 75, 2017<br>
  <br>
  StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial
  Networks.H Zhang, T Xu, H Li, S Zhang, X Wang, X Huang, D Metaxas. arXiv
  preprint arXiv:1710.10916, 2017<br>
  <br>
  Stackgan: Text to photo-realistic image synthesis with stacked generative
  adversarial networks.H Zhang, T Xu, H Li, S Zhang, X Wang, X Huang, D
  Metaxas. IEEE Int. Conf. Comput. Vision (ICCV), 5907-5915, 2017. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Pre-requisites</span></b><span style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Calculus and PDEs, Basic Optimization Methods, Deep Neural Nets, Numerical
  analysis. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="27%" colspan=2 valign=top style='width:27.52%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Jose C. Principe, University of
  Florida<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Cognitive Architectures for Object Recognition in
  Video<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTRODUCTORY/ADVANCED<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Syllabus</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  I-Requisites for a Cognitive Architecture<br>
  • Processing in space<br>
  • Processing in time and memory<br>
  • Top down and bottom processing<br>
  • Extraction of information from data with generative models<br>
  • Attention<br>
  II- Putting it all together<br>
  • Empirical Bayes with generative models <br>
  • Clustering of time series with linear state models<br>
  • Information Theoretic Autoencoders<br>
  III- Current work<br>
  • Extraction of time signatures with kernel ARMA<br>
  • Attention Based video recognition<br>
  • Augmenting Deep Learning with memory <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>References</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Pre-requisites</span></b><span style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-no-proof:yes'><o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.5%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Björn Schuller, Imperial
  College London<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Deep Learning for Signal Analysis<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTERMEDIATE/ADVANCED<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  This course will deal with injection of deep learning algorithms into multimodal
  and multisensorial signal analysis such as from audio, video, or
  physiological signals. Methods shown will, however, be applicable to a broad
  range of further signals. We will first deal with pre-processing such as by
  autoencoders and feature representation learning such as by convolutional
  neural networks first as basis for end-to-end learning from raw signals.
  Then, we shall discuss modelling for decision making such as by recurrent
  neural networks with long-short-term memory or gated recurrent units. We will
  also elaborate on the impact of topologies including multiple targets with
  shared layers and bottlenecks, and how to move towards self-shaping networks
  in the sense of Automatic Machine Learning. In a last part, we will deal with
  data efficiency, such as by weak supervision with the human in the loop based
  on active and semi-supervised learning, transfer learning, or generative
  adversarial networks. The content shown will be accompanied by open-source
  implementations of according toolkits available on github. Application
  examples will come from the domains of Affective Computing, Multimedia
  Retrieval, and mHealth. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Syllabus</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  1) Pre-Processing and Feature Representation Learning (AEs, CNNs, end-to-end)<br>
  2) Modelling for Decision Making (Feature Space Optimisation, Topologies,
  AutoML)<br>
  3) Data Efficiency (GANs, Transfer Learning, Weak Supervision) <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>References</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  The Handbook of Multimodal-Multisensor Interfaces. Vol. 2, S. Oviatt, B.
  Schuller, P.R. Cohen, D. Sonntag, G. Potamianos, A. Krüger (eds.), 2018 (forthcoming)
  <a href="https://github.com/end2you/end2you">https://github.com/end2you/end2you</a>
  <br>
  <a href="https://github.com/openXBOW/openXBOW">https://github.com/openXBOW/openXBOW</a>
  <br>
  <a href="https://github.com/auDeep/auDeep">https://github.com/auDeep/auDeep</a>
  <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Pre-requisites</span></b><span style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Attendees should be familiar with Machine Learning and Neural Networks in
  general. They should further have basic knowledge of Signal Processing. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
 </tr>
 <tr style='mso-yfti-irow:5;page-break-inside:avoid'>
  <td width="15%" valign=top style='width:15.5%;border:none;background:#FF78E4;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Th,
  9:30-11:15<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Th,
  16:45-18:30<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Fr,
  11:45-13:30<o:p></o:p></span></b></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.48%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Thomas Breuel, NVIDIA
  Corporation<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Design and Implementation of Deep Learning
  Applications<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTERMEDIATE<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  - relationships between deep learning and decision theory, Bayesian methods<br>
  - risk estimation and minimization for deep learning<br>
  - empirical evaluation of deep learning algorithms<br>
  - equivalences between deep learning methods and classical machine learning,
  detection theory, image processing, and computer vision<br>
  - generating synthetic data using deep learning methods, adversarial methods,
  channel models<br>
  - multidimensional recurrent neural networks and their applications<br>
  - large scale distributed deep learning with petascale datasets and many GPUs<br>
  Examples<br>
  --------<br>
  will be drawn from autonomous vehicles, large scale text recognition, visual
  object recognition, and semantics segmentation. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Syllabus</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>References</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Pre-requisites</span></b><span style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-no-proof:yes'><o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="27%" colspan=2 valign=top style='width:27.52%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Michèle Sebag, French National
  Center for Scientific Research, Gif-sur-Yvette<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Representation Learning, Domain Adaptation and
  Generative Models with Deep Learning<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTERMEDIATE<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><br>
Within Deep Learning, representation learning is seamlessly integrated within the whole machine learning process, with utmost benefits when facing domains with raw high-dimensional description such as computer vision or natural language programming. Domain adaptation is concerned with the ability of transferring models learned from a so-called source domain (typically with many labelled examples) to a target domain with few or no labels, making learning faster and/or more effective. Generative learning is concerned with the ability to learn a distribution representative of the available data sample. The course will be followed by an (optional) hands-on, as a challenge on Codalab. (url available on July 15th).<br>
<br>
   <b>Syllabus</b><br>
Lecture 1: Introduction to Transfer Learning and Domain Adaptation<br>
* Motivations<br>
* Main approaches: mapping the target onto the source; mapping both source and target onto a same latent representation.<br>
* Criteria and algorithms; distances between distributions, strengths and weaknesses<br>
<br>
Lecture 2: Generative learning<br>
* Auto-Encoders<br>
* Variational Auto-Encoders<br>
* Generative Adversarial Networks<br>
<br>
Lecture 3: DA Algorithms<br>
* Domain adaptation with optimal transport<br>
* Domain Adversarial Training of Neural Networks<br>
* Recent algorithms: CycleGAN, UNIT.<br>
<br>
<b>References</b><br>
* Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. A theory of learning from different domains. Machine Learning, 79(1-2):151–175, 2010<br>
* Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NIPS, 2014.<br>
* Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, Mario Marchand, Victor Lempitsky. Domain-Adversarial Training of Neural Networks, Journal of Machine Learning Research 17 (2016) 1-35.<br>
* Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros: Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks. ICCV 2017: 2242-2251<br>
* Ming-Yu Liu, Thomas Breuel, Jan Kautz: Unsupervised Image-to-Image Translation Networks. NIPS 2017: 700-708<br>
* Nicolas Courty, Rémi Flamary, Amaury Habrard, Alain Rakotomamonjy: Joint distribution optimal transportation for domain adaptation. NIPS 2017: 3733-3742<br>
<br>
<b>Pre-requisites</b><br>
Level : intermediate/advanced<br>
Requirement : basic knowledge of neural networks and probability theory/statistics <o:p></o:p></span></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.5%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Kenji Suzuki, Tokyo Institute
  of Technology<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Deep Learning in Medical Image Processing, Analysis
  and Diagnosis<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTRODUCTORY/ADVANCED<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  It is said that artificial intelligence driven by deep learning would make
  the 4th Industrial Evolution. As is true in many other fields, deep leaning
  becomes one of the most active areas of research in the fields of medical
  image analysis and computer-aided diagnosis, because “learning from examples
  or data” is crucial to handling a large amount of data (“big data”) coming
  from medical imaging systems. Deep learning is a versatile, powerful
  framework that can acquire image-processing and analysis functions through
  training with image examples; and it is an end-to-end machine-learning model
  that enables a direct mapping from raw input data to desired outputs,
  eliminating the need for handcrafted features in conventional feature-based
  machine learning. I invented ones of the earliest deep-learning models for
  image processing, semantic segmentation, lesion enhancement, and removal of
  specific patterns in medical imaging to make the tasks that conventional
  methods had not been able to do possible, and I have been actively studying
  on deep learning in medical imaging in the past 20 years or so. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Syllabus</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  In my tutorials, machine learning and deep learning are described together
  with their applications in the biomedical field. First, fundamentals of
  machine learning are reviewed briefly before entering into the topic of deep
  learning, because deep learning is advanced machine learning. Then, the
  history of deep learning is overviewed. The fundamentals, architectures,
  training, and practical issues of deep learning are described to make clear
  a) what has changed in machine learning after the introduction of deep
  learning, b) differences and advantages over conventional feature-based
  machine learning, and c) deep learning applications to 1) computer-aided
  diagnosis for lung nodule detection in chest radiography and thoracic CT, 2)
  distinction between benign and malignant nodules in CT, 3) polyp detection
  and classification in CT colonography, 4) separation of bones from soft
  tissue in chest radiographs, 5) semantic segmentation of organs and lesions
  in medical images, and 6) radiation dose reduction by improving the image
  quality of low-dose CT and mammography. My tutorials include:<br>
  1. Fundamentals of machine learning<br>
  2. Neural networks (biological analogy, multilayer perceptrons,
  back-propagation learning algorithm, practical design and training issues)<br>
  3. History of deep learning<br>
  4. Mathematical and biological preliminaries of deep learning<br>
  5. Relations to human visual systems (multiple-channel models, visual
  learning models, hierarchical structure of the human visual systems, model
  and knowledge acquisitions, data representations in the brain)<br>
  6. Representative deep learning models including deep convolutional neural
  networks (DCNN), deep residual neural networks, generative adversarial
  networks (GAN), and massive-training artificial neural networks (MTANN)<br>
  7. Foundations, architectures, and practical issues of DCNN<br>
  8. Comparisons between DCNN and MTANN<br>
  9. Applications of deep learning (object recognition, lesion detection and
  classification, computer-aided diagnosis, denoising, image processing, image
  restoration, semantic segmentation, removal of specific patterns, and
  enhancement of lesions)<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>References</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  1. LeCun Y, Bengio Y, Hinton G, Deep learning, Nature: 521, pp. 436–444,
  2015.<br>
  2. Suzuki K.: Overview of Deep Learning in Medical Imaging. Radiological
  Physics and Technology 10(3): 257-273, 2017.<br>
  3. A. Krizhevsky, I. Sutskever, G. E. Hinton, ImageNet classification with
  deep convolutional neural networks, Advances in Neural Information Processing
  Systems, 25, pp. 1097–1105. 2012, <br>
  4. Nima T. and Suzuki K.: Comparing Two Classes of End-to-End Learning
  Machines for Lung Nodule Detection and Classification: MTANNs vs. CNNs.
  Pattern Recognition 63: 476–486, 2017<br>
  5. Suzuki K.: Editor. Machine Learning in Computer-Aided Diagnosis: Medical
  Imaging Intelligence and Analysis, IGI Global (Hershey, PA), 524 pp., 2012.
  (ISBN 9781466600591) <br>
  6. Suzuki K.: Editor. Computational Intelligence in Biomedical Imaging,
  Springer (New York, NY), 411 pp., 2014. (ISBN 978-1-4614-7244-5)<br>
  7. Suzuki K., Chen Y.: Editors. Artificial Intelligence in Decision Support
  Systems for Diagnosis in Medical Imaging, Springer-Nature, (Switzerland), 387
  pp., 2018. (ISBN 978-3-319-68842-8)<br>
  8. Suzuki K., Horiba I., Sugie N., and Ikeda S.: Improvement of image quality
  of x-ray fluoroscopy using spatiotemporal neural filter which learns noise
  reduction, edge enhancement and motion compensation. Proc. Int. Conf. Signal
  Processing Applications and Technology (ICSPAT) 2: 1382-1386, 1996. <br>
  9. Suzuki K., Horiba I., and Sugie N.: Efficient approximation of neural
  filters for removing quantum noise from images. IEEE Transactions on Signal
  Processing 50: 1787-1799, 2002.<br>
  10. Suzuki K., Armato III S. G., Li F., Sone S., and Doi K.: Massive training
  artificial neural network (MTANN) for reduction of false positives in
  computerized detection of lung nodules in low-dose CT. Medical Physics 30:
  1602-1617, 2003. <br>
  11. Suzuki K., Horiba I., and Sugie N.: Neural edge enhancer for supervised
  edge enhancement from noisy images. IEEE Transactions on Pattern Analysis and
  Machine Intelligence 25: 1582-1596, 2003.<br>
  12. Suzuki K., Horiba I., Sugie N., and Nanki M.: Extraction of left
  ventricular contours from left ventriculograms by means of a neural edge
  detector. IEEE Transactions on Medical Imaging 23: 330-339, 2004.<br>
  13. Suzuki K.: Determining the receptive field of a neural filter. Journal of
  Neural Engineering 1: 228-237, 2004.<br>
  14. Suzuki K., Li F., Sone S., and Doi K.: Computer-aided diagnostic scheme
  for distinction between benign and malignant nodules in thoracic low-dose CT
  by use of massive training artificial neural network. IEEE Transactions on
  Medical Imaging 24: 1138-1150, 2005.<br>
  15. Suzuki K., and Doi K.: How can a massive training artificial neural
  network (MTANN) be trained with a small number of cases in the distinction
  between nodules and vessels in thoracic CT? Academic Radiology 12: 1333-1341,
  2005.<br>
  16. Suzuki K., Abe H., MacMahon H., and Doi K.: Image-processing technique
  for suppressing ribs in chest radiographs by means of massive training
  artificial neural network (MTANN). IEEE Transactions on Medical Imaging 25:
  406-416, 2006.<br>
  17. Suzuki K.: Supervised “lesion-enhancement” filter by use of a
  massive-training artificial neural network (MTANN) in computer-aided
  diagnosis (CAD). Physics in Medicine and Biology 54: S31-S45, 2009.<br>
  18. Suzuki K.: Pixel-Based Machine Learning in Medical Imaging. International
  Journal of Biomedical Imaging 2012: Article ID 792079, 18 pages, 2012.<br>
  19. Chen S. and Suzuki K.: Separation of Bones from Chest Radiographs by
  Means of Anatomically Specific Multiple Massive-Training ANNs Combined with
  Total Variation Minimization Smoothing. IEEE Transactions on Medical Imaging
  33: 246-257, 2014.<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Pre-requisites</span></b><span style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-no-proof:yes'><br>
  There is no pre-requisite for the tutorials, but enthusiasms for learning
  deep learning in medicine and healthcare are 'required.' <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
 </tr>
 <tr style='mso-yfti-irow:6'>
  <td width="15%" valign=top style='width:15.5%;border:none;background:#D47A00;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Th,
  14:30-16:15<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Fr,
  9:30-11:15<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Fr,
  16:45-18:30<o:p></o:p></span></b></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.48%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Namkug Kim, Asan Medical Center<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Deep Learning for Computer Aided Detection/Diagnosis
  in Radiology and Pathology<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTERMEDIATE<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Medical imaging is getting more important in modern medicine including
  radiology, pathology, surgery, neuroscience, etc. In case of radiology, there
  are several shortcomings in case of typical diagnostic radiology, due to the
  qualitative reading of a human observer. In addition, the rapid development
  of recent medical imaging equipment which produce a tremendous amount of
  image data makes the typical medical image reading nearly impractical.
  Recently, deep learning shows better accuracy for detection and classification
  in computer vision, which could be rapidly applied to medical imaging areas.
  I'll introduce methodology of data science including machine learning, and
  deep learning, and deep learning based applications in computer vision,
  computer aided diagnosis in radiology and pathology. In addition, I'll
  suggest some practical considerations on application of these technology to
  clinical workflow including efficient labeling technology, interpretability
  and visualization (No blackbox), uncertainty (Data level, Decision level),
  reproducibility of deep learning, novelty in supervised learning, one-shot or
  multi-shot learning due to Imbalanced data set or rare disease, deep
  survival, and physics induced machine learning. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Syllabus</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  1. Introduction to data science, machine learning, and deep learning<br>
  2. Deep learning in computer vision and applicaions<br>
  3. Deep learning for computer aided detection/diagnosis in radiology<br>
  4. Deep learning for computer aided detection/diagnosis in pathology <br>
  5. Practical consideration for deep learning application in medicine<br>
  - efficient labeling technology <br>
  - Interpretability and visualization (No blackbox)<br>
  - Uncertainty (Data level, Decision level)<br>
  - Reproducibility of deep learning<br>
  - Novelty in supervised learning <br>
  - One-shot or multi-shot learning due to Imbalanced data set or rare disease <br>
  - Deep survival<br>
  - Physics induced machine learning <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>References</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Deep into the Brain: Artificial Intelligence in Stroke Imaging., Lee EJ, Kim YH,
  Kim N, Kang DW., J Stroke. 2017 Sep;19(3):277-285. doi:
  10.5853/jos.2017.02054. Epub 2017 Sep 29. Review.<br>
  Comparison of Shallow and Deep Learning Methods on Classifying the Regional
  Pattern of Diffuse Lung Disease, Guk Bae Kim, Kyu-Hwan Jung, Yeha Lee,
  Hyun-Jun Kim, Namkug* Kim, Sanghoon Jun, Joon Beom Seo, David A. Lynch,
  Journal of Digital Imaging, 17 October 2017 (co-CA)<br>
  Development of a Computer-Aided Differential Diagnosis System to Distinguish
  Between Usual Interstitial Pneumonia and Non-specific Interstitial Pneumonia
  Using Texture- and Shape-Based Hierarchical Classifiers on HRCT Images. Jun
  S, Park B, Seo JB, Lee S, Kim N*. J Digit Imaging. 2017 Sep 7. doi:
  10.1007/s10278-017-0018-y. PMID: 28884381 [PubMed – as supplied by publisher]
  (co-CA)<br>
  Deep Learning in Medical Imaging: General Overview. Lee JG, Jun S, Cho YW,
  Lee H, Kim GB, Seo JB, Kim N*. Korean J Radiol. 2017 Jul-Aug;18(4):570-584.
  doi: 10.3348/kjr.2017.18.4.570. Epub 2017 May 19. Review PMID: 28670152
  [PubMed – in process]<br>
  Deep Learning: A Primer for Radiologists, Gabriel Chartrand, et al,
  Radiographics, Volume 37, Issue 7, 2017 <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Pre-requisites</span></b><span style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Basic knowledge of computer algorithms and software; knowledge of machine
  learning and deep learning is recommended. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="27%" colspan=2 valign=top style='width:27.52%;border:none;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Li Erran Li, Uber ATG<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Deep Reinforcement Learning: Foundations, Recent
  Advances and Frontiers<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTERMEDIATE/ADVANCED<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Deep reinforcement learning has enabled artificial agents to achieve
  human-level performances across many challenging domains, e.g. playing Atari
  games and Go. I will cover the foundations of reinforcement learning, present
  several important algorithms including deep Q-Networks and asynchronous
  actor-critic algorithms (A3C), DDPG, SVG, guided policy search, TDM. I will
  discuss major challenges and promising results towards making deep
  reinforcement learning applicable to real world problems in robotics and
  natural language processing. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Syllabus</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  1. Introduction to reinforcement learning (RL)<br>
  2. Value-based deep RL<br>
  Deep Q-learning (deep Q-Networks)<br>
  Temporal-difference model (TDM)<br>
  3. Policy-based deep RL<br>
  Policy gradients<br>
  Asynchronous actor-critic algorithms (A3C)<br>
  Natural gradients and trust region optimization (TRPO)<br>
  Deep deterministic policy gradients (DDPG), SVG<br>
  4. Model-based deep RL: guided policy search<br>
  5. Deep learning in multi-agent environment: fictitious self-play<br>
  6. Imitation learning: GAIL and InfoGAIL<br>
  7. Exploration<br>
  8. Inverse RL<br>
  9. Transfer learning, multitask learning and meta learning in RL<br>
  10. Frontiers<br>
  Application to robotics<br>
  Application to natural language understanding <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>References</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  V. Pong, S. Gu, M. Dalal, S. Levine, Temporal Difference Models: Model-Free
  Deep RL for Model Based Control, ICLR 2018<br>
  <br>
  B., and de Freitas, N. (2016). Learning to learn by gradient descent by
  gradient descent. In the Annual Conference on Neural Information Processing
  Systems (NIPS).<br>
  <br>
  Asri, L. E., He, J., and Suleman, K. (2016). A sequence-to-sequence model for
  user simulation in spoken dialogue systems. In Annual Meeting of the
  International Speech Communication Association (INTERSPEECH).<br>
  <br>
  Babaeizadeh, M., Frosio, I., Tyree, S., Clemons, J., and Kautz, J. (2017).
  Reinforcement learning through asynchronous advantage actor-critic on a gpu.
  Submitted to Int’l Conference on Learning Representations.<br>
  <br>
  Bahdanau, D., Brakel, P., Xu, K., Goyal, A., Lowe, R., Pineau, J., Courville,
  A., and Bengio, Y. (2017). An actor-critic algorithm for sequence prediction.
  Submitted to Int’l Conference on Learning Representations.<br>
  <br>
  Chebotar, Y., Kalakrishnan, M., Yahya, A., Li, A., Schaal, S., and Levine, S.
  (2016). Path integral guided policy search. ArXiv e-prints.<br>
  <br>
  Deng, L. and Liu, Y. (2017). Deep Learning in Natural Language Processing
  (edited book, scheduled August 2017). Springer.<br>
  <br>
  Dhingra, B., Li, L., Li, X., Gao, J., Chen, Y.-N., Ahmed, F., and Deng, L.
  (2016). End-to-End Reinforcement Learning of Dialogue Agents for Information
  Access. ArXiv e-prints. Domingos, P. (2012). A few useful things to know
  about machine learning. Communications of the ACM, 55(10):78–87.<br>
  <br>
  Dulac-Arnold, G., Evans, R., van Hasselt, H., Sunehag, P., Lillicrap, T.,
  Hunt, J., Mann, T., Weber, T., Degris, T., and Coppin, B. (2016). Deep
  reinforcement learning in large discrete action spaces In the International
  Conference on Machine Learning (ICML).<br>
  <br>
  Finn, C., Christiano, P., Abbeel, P., and Levine, S. (2016). A connection
  between GANs, inverse reinforcement learning, and energy-based models. In
  NIPS 2016 Workshop on Adversarial Training.<br>
  <br>
  Finn, C. and Levine, S. (2016). Deep visual foresight for planning robot
  motion. ArXiv e-prints.<br>
  <br>
  Finn, C., Yu, T., Fu, J., Abbeel, P., and Levine, S. (2017). Generalizing
  skills with semi supervised reinforcement learning. Submitted to Int’l
  Conference on Learning Representations.<br>
  <br>
  Florensa, C., Duan, Y., and Abbeel, P. (2017). Stochastic neural networks for
  hierarchical reinforcement learning. Submitted to Int’l Conference on
  Learning Representations.<br>
  <br>
  García, J. and Fernández, F. (2015). A comprehensive survey on safe
  reinforcement learning. The Journal of Machine Learning Research, 16:1437–1480.
  <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Pre-requisites</span></b><span style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Basic knowledge of reinforcement learning, deep learning and Markov decision
  processes <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="28%" colspan=2 style='width:28.5%;border:none;padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal align=center style='margin-bottom:0cm;margin-bottom:.0001pt;
  text-align:center;line-height:normal'><span lang=EN-US style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:
  yes'>- / -<o:p></o:p></span></p>
  </td>
 </tr>
 <tr style='mso-yfti-irow:7;mso-yfti-lastrow:yes'>
  <td width="15%" valign=top style='width:15.5%;border:none;border-bottom:solid black 1.0pt;
  mso-border-bottom-themecolor:text1;background:#3DA700;padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Th,
  19:00-20:45<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Fr,
  14:30-16:15<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal;mso-yfti-cnfc:4'><b><span lang=EN-US style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-ansi-language:EN-US;mso-no-proof:yes'>Fr,
  19:00-20:45<o:p></o:p></span></b></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.48%;border:none;
  border-bottom:solid black 1.0pt;mso-border-bottom-themecolor:text1;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Douglas A. Reynolds &amp; Najim
  Dehak, Massachusetts Institute of Technology &amp; Johns Hopkins University<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>More than Words can Say: Machine and Deep Learning
  for Speaker, Language, and Emotion Recognition from Speech<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTRODUCTORY/INTERMEDIATE<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Speech conveys many types of information to the listener. Beyond just the
  words, the speech signal provides information about what language is being
  spoken, who is speaking, the emotional state of the speaker, and the acoustic
  environment in which the speech is occurring. Such extra-word information can
  be useful for many areas such as secure access, device personalization, audio
  searching, and medical interactions. Powerful machine learning techniques,
  including statistical, geometric, and neural pattern recognition, have been
  successfully applied over several decades to successfully and effectively
  build systems for automatically recognizing these types of characteristics
  from challenging, real-world speech recordings. In this tutorial we will
  introduce the audience to the fundamentals behind speaker, language, and
  emotion recognition, going from the science behind speech production to the
  machine learning building blocks underpinning modern recognition systems. We
  will describe the details of implementing these recognition systems covering
  the critical role of data in the training and testing of systems. Important
  areas of domain adaptation, channel compensation, diarization, and effective
  evaluation design and interpretation will also be covered. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Syllabus</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  tbc. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>References</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  D. A. Reynolds, T. F. Quatieri, R. B. Dunn, 'Speaker verification using
  adapted Gaussian mixture models', Digital signal processing 10 (1-3), 19-41 F
  Bimbot, et al, 'A tutorial on text-independent speaker verification', EURASIP
  Journal on Advances in Signal Processing 2004<br>
  T. Kinnunen, H. Li, 'An overview of text-independent speaker recognition:
  From features to supervectors', Speech Communication, Volume 52, Issue 1,
  2010, Pages 12-40<br>
  N. Dehak, P. J. Kenny, R. Dehak, P. Dumouchel and P. Ouellet, 'Front-End
  Factor Analysis for Speaker Verification,' in IEEE Transactions on Audio,
  Speech, and Language Processing, vol. 19, no. 4, pp. 788-798, May 2011<br>
  N Dehak, PA Torres-Carrasquillo, D Reynolds, R Dehak, 'Language recognition
  via i-vectors and dimensionality reduction', Interspeech 2012<br>
  F. Richardson, D. Reynolds and N. Dehak, 'Deep Neural Network Approaches to
  Speaker and Language Recognition,' in IEEE Signal Processing Letters, vol.
  22, no. 10, pp. 1671-1675, Oct. 2015<br>
  D Snyder, D Garcia-Romero, G Sell, D Povey, 'X-vectors: Robust DNN embeddings
  for speaker recognition', ICASSP 2018 <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Pre-requisites</span></b><span style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Some knowledge of digital signal processing, probability and statistics, and
  linear algebra <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="27%" colspan=2 valign=top style='width:27.52%;border:none;
  border-bottom:solid black 1.0pt;mso-border-bottom-themecolor:text1;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>René Vidal, Johns Hopkins
  University<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Mathematics of Deep Learning<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTERMEDIATE/ADVANCED<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  The past few years have seen a dramatic increase in the performance of
  recognition systems thanks to the introduction of deep networks for
  representation learning. However, the mathematical reasons for this success
  remain elusive. For example, a key issue is that the neural network training
  problem is nonconvex, hence optimization algorithms are not guaranteed to
  return a global minima. The first part of this tutorial will overview recent
  work on the theory of deep learning that aims to understand how to design the
  network architecture, how to regularize the network weights, and how to
  guarantee global optimality. The second part of this tutorial will present
  sufficient conditions to guarantee that local minima are globally optimal and
  that a local descent strategy can reach a global minima from any
  initialization. Such conditions apply to problems in matrix factorization,
  tensor factorization and deep learning. The third part of this tutorial will
  present an analysis of dropout for matrix factorization, and establish
  connections <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Syllabus</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  1. Introduction to Deep Learning Theory: Optimization, Regularization and
  Architecture Design<br>
  2. Global Optimality in Matrix Factorization<br>
  3. Global Optimality in Tensor Factorization and Deep Learning<br>
  4. Dropout as a Low-Rank Regularizer for Matrix Factorization <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>References</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  <a href="https://arxiv.org/abs/1712.04741">https://arxiv.org/abs/1712.04741</a>
  <br>
  <a href="https://arxiv.org/abs/1708.07850">https://arxiv.org/abs/1708.07850</a>
  <br>
  <a
  href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Haeffele_Global_Optimality_in_CVPR_2017_paper.pdf">http://openaccess.th..._CVPR_2017_paper.pdf</a><br>
  <a href="https://arxiv.org/abs/1506.07540">https://arxiv.org/abs/1506.07540</a>
  <br>
  <a href="https://arxiv.org/abs/1710.05092">https://arxiv.org/abs/1710.05092</a><span
  style='mso-spacerun:yes'>  </span><o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Pre-requisites</span></b><span style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Basic understanding of sparse and low-rank representation and non-convex
  optimization. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
  <td width="28%" colspan=2 valign=top style='width:28.5%;border:none;
  border-bottom:solid black 1.0pt;mso-border-bottom-themecolor:text1;
  padding:0cm 5.4pt 0cm 5.4pt'>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>Ming-Hsuan Yang, University of
  California, Merced<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b style='mso-bidi-font-weight:normal'><span lang=EN-US
  style='color:black;mso-themecolor:text1;mso-themeshade:191;mso-ansi-language:
  EN-US;mso-no-proof:yes'>Learning to Track Objects<o:p></o:p></span></b></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'>INTERMEDIATE/ADVANCED<o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Summary</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  The goal is to introduce the recent advances in object tracking based on deep
  learning and related approaches. Performance evaluation and challenging
  factors in this field will be discussed. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Syllabus</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Brief history of visual tracking<br>
  Generative approach<br>
  Discriminative approach<br>
  Deep learning methods<br>
  Performance evaluation<br>
  Challenges and future research directions <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>References</span></b><span style='color:black;mso-themecolor:
  text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Y. Wu, J. Lim, and M.-H. Yang, Object Tracking Benchmark, IEEE Transactions
  on Pattern Analysis and Machine Intelligence, 2015.<br>
  H. Nam and B. Han, Learning Multi-domain Convolutional Neural Networks for
  Visual Tracking, CVPR, 2016.<br>
  M. Danelljan, G. Bhat, F. Khan, M. Felsberg, ECO: Efficient Convolution
  Operators for Tracking. CVPR, 2017. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><b><span style='color:black;mso-themecolor:text1;mso-themeshade:191;
  mso-no-proof:yes'>Pre-requisites</span></b><span style='color:black;
  mso-themecolor:text1;mso-themeshade:191;mso-no-proof:yes'><br>
  Basic knowledge in computer vision and intermediate knowledge in deep
  learning. <o:p></o:p></span></p>
  <p class=MsoNormal style='margin-bottom:0cm;margin-bottom:.0001pt;line-height:
  normal'><span lang=EN-US style='color:black;mso-themecolor:text1;mso-themeshade:
  191;mso-ansi-language:EN-US;mso-no-proof:yes'><o:p>&nbsp;</o:p></span></p>
  </td>
 </tr>
 <![if !supportMisalignedColumns]>
 <tr height=0>
  <td width=81 style='border:none'></td>
  <td width=254 style='border:none'></td>
  <td width=5 style='border:none'></td>
  <td width=357 style='border:none'></td>
  <td width=3 style='border:none'></td>
  <td width=330 style='border:none'></td>
  <td width=10 style='border:none'></td>
 </tr>
 <![endif]>
</table>

<p class=MsoNormal><span lang=EN-US style='mso-ansi-language:EN-US;mso-no-proof:
yes'><o:p>&nbsp;</o:p></span></p>

</div>

</body>

</html>
